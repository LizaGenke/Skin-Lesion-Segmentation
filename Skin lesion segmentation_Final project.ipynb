{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skin lesion segmentation #\n",
    "This project has been made as a final assesment of the course Advanced Image Analysis in the University of Cassino and Southern Lazio by Elizaveta Genke, Mladen Rakic, Liliana Valencia Rodriguez, Daria Zotova."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from skimage import io \n",
    "from skimage import img_as_ubyte\n",
    "from skimage import color\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.measure import label\n",
    "from skimage.measure import regionprops\n",
    "from skimage import morphology\n",
    "from skimage.morphology import disk\n",
    "from skimage.morphology import rectangle\n",
    "from skimage import filters\n",
    "from skimage.filters import gaussian\n",
    "from skimage.transform import rescale\n",
    "\n",
    "import scipy\n",
    "import scipy.ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hair_removal (img_input):\n",
    "    \n",
    "    # input arguments:\n",
    "    # img_input - original color image\n",
    "    #\n",
    "    # output arguments:\n",
    "    # img_output - color image with hairs suppressed \n",
    "    \n",
    "    img_gray = color.rgb2gray(img_input)\n",
    "    \n",
    "    # blur the original image\n",
    "    img_gray_blurred = cv2.GaussianBlur(img_gray,(5,5),0)\n",
    "\n",
    "    # compute laplacian to obtain a sharpened result\n",
    "    img_laplacian = scipy.ndimage.filters.laplace(img_gray_blurred)\n",
    "    img_subtraction = img_gray_blurred - img_laplacian\n",
    "    \n",
    "    # perform bottom hat transformation by rotating line kernel \n",
    "    kernel_line = np.ones((10,50),np.uint8)\n",
    "    img_bottom_hat_1 = cv2.morphologyEx(img_subtraction, cv2.MORPH_BLACKHAT, kernel_line)\n",
    "    kernel_line_rotated_45 = scipy.ndimage.interpolation.rotate(kernel_line, 45)\n",
    "    img_bottom_hat_2 = cv2.morphologyEx(img_subtraction, cv2.MORPH_BLACKHAT, kernel_line_rotated_45)\n",
    "    kernel_line_rotated_90 = scipy.ndimage.interpolation.rotate(kernel_line_rotated_45, 45)\n",
    "    img_bottom_hat_3 = cv2.morphologyEx(img_subtraction, cv2.MORPH_BLACKHAT, kernel_line_rotated_90)\n",
    "    img_addition = img_bottom_hat_1 + img_bottom_hat_2 + img_bottom_hat_3\n",
    "    \n",
    "    # threshold the obtained result\n",
    "    threshold = np.amax(img_addition) * 0.2\n",
    "    ret, img_binary = cv2.threshold(img_addition,threshold,1.0,cv2.THRESH_BINARY)\n",
    "    \n",
    "    # dilate the binary image\n",
    "    kernel_dilation = np.ones((1,10),np.uint8)\n",
    "    img_dilated = cv2.dilate(img_binary,kernel_dilation,iterations = 1)\n",
    "    img_dilated = np.uint8(img_dilated)\n",
    "    \n",
    "    # perform the inpainting technique\n",
    "    img_output = cv2.inpaint(img_input, img_dilated, 20, cv2.INPAINT_TELEA)\n",
    "    \n",
    "    return img_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanshift_segmentation (img_input):\n",
    "    \n",
    "    # input arguments:\n",
    "    # img_input - color image with hairs suppressed \n",
    "    #\n",
    "    # output arguments:\n",
    "    # img_output - binary meanshift segmented image\n",
    "    \n",
    "    # perform meanshift filtering\n",
    "    img_meanshift = cv2.pyrMeanShiftFiltering(img_input, 30, 40)\n",
    "    img_gray = color.rgb2gray(img_meanshift)\n",
    "    \n",
    "    # convert float grayscale image into int\n",
    "    img_min = img_gray.min()\n",
    "    img_max = img_gray.max()\n",
    "    img_copy = img_gray.copy()\n",
    "\n",
    "    for i in range (img_gray.shape[0]):\n",
    "        for j in range (img_gray.shape[1]):\n",
    "            img_copy[i][j] = (img_gray[i][j] - img_min) / (img_max - img_min) * 255\n",
    "    img_copy = np.uint8(img_copy)\n",
    "    \n",
    "    # remove dark regions based on histogram\n",
    "    hist_values, bins_edges = np.histogram(img_copy,256)\n",
    "    if hist_values[0] > 10000:\n",
    "        img_copy = dark_region_removal(img_copy)\n",
    "    \n",
    "    ret,img_binary = cv2.threshold(img_copy,120,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    img_output = 255 - img_binary\n",
    "    \n",
    "    return img_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def watershed_segmentation (img_original,img_hairless):\n",
    "    \n",
    "    # input arguments:\n",
    "    # img_original - original color image\n",
    "    # img_hairless - color image with hairs suppressed\n",
    "    #\n",
    "    # output arguments:\n",
    "    # img_output - binary watershed segmented image\n",
    "\n",
    "    # convert to binary and change the data type\n",
    "    img_hairless_gray = color.rgb2gray(img_hairless)\n",
    "    \n",
    "    img_min = img_hairless_gray.min()\n",
    "    img_max = img_hairless_gray.max()\n",
    "    img_copy = img_hairless_gray.copy()\n",
    "    \n",
    "    for i in range (img_hairless_gray.shape[0]):\n",
    "        for j in range (img_hairless_gray.shape[1]):\n",
    "            img_copy[i][j] = (img_hairless_gray[i][j] - img_min) / (img_max - img_min) * 255\n",
    "    img_copy = np.uint8(img_copy)\n",
    "    \n",
    "    # remove dark regions based on histogram\n",
    "    hist_values, bins_edges = np.histogram(img_copy,256)\n",
    "    if hist_values[0] > 10000:\n",
    "        img_copy = dark_region_removal(img_copy)\n",
    "\n",
    "    ret,img_binary = cv2.threshold(img_copy,120,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    img_binary = 255 - img_binary\n",
    "\n",
    "    # find foreground area\n",
    "    dist_transform = cv2.distanceTransform(img_binary,cv2.DIST_L2,0)\n",
    "    ret, foreground = cv2.threshold(dist_transform,0.05*dist_transform.max(),255,0)\n",
    "\n",
    "    # find background region\n",
    "    foreground = np.uint8(foreground)\n",
    "    background = cv2.subtract(img_binary,foreground)\n",
    "\n",
    "    # label markers\n",
    "    ret, markers = cv2.connectedComponents(foreground)\n",
    "\n",
    "    # add one to all labels so that background is not 0, but 1\n",
    "    markers = markers+1\n",
    "    \n",
    "    # mark the region of background with zero\n",
    "    markers[background == 255] = 0\n",
    "    \n",
    "    # apply watershed \n",
    "    markers = cv2.watershed(img_original,markers)\n",
    "    img_original[markers == -1] = [255,0,0]\n",
    "    \n",
    "    # change the data type of the output from int32 to uint8\n",
    "    min_marker = markers.min()\n",
    "    max_marker = markers.max()\n",
    "    new_marker = markers.copy()\n",
    "\n",
    "    for i in range (markers.shape[0]):\n",
    "        for j in range (markers.shape[1]):\n",
    "            new_marker[i][j] = (markers[i][j]-min_marker)/(max_marker-min_marker)*255\n",
    "        \n",
    "    new_marker = np.uint8(new_marker)\n",
    "    ret,img_binary_final = cv2.threshold(img_binary,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    \n",
    "    # perform morphological opening\n",
    "    kernel = np.ones((10,10),np.float32)/100\n",
    "    img_output = cv2.morphologyEx(img_binary_final,cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    return img_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dark_region_removal (img_input):\n",
    "    \n",
    "    # input arguments:\n",
    "    # img_input - grayscale image\n",
    "    #\n",
    "    # output arguments:\n",
    "    # img_output - grayscale image with dark regions suppressed\n",
    "    \n",
    "    for i in range (img_input.shape[0]):\n",
    "        for j in range (img_input.shape[1]):\n",
    "            if (img_input[i][j] < 50):\n",
    "                img_input[i][j] = 125\n",
    "    \n",
    "    img_output = img_input\n",
    "    \n",
    "    return img_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_extraction (img_input):\n",
    "    \n",
    "    # input arguments:\n",
    "    # img_input - binary image \n",
    "    #\n",
    "    # output arguments:\n",
    "    # img_output - segmented binary image\n",
    "    \n",
    "    # remove small holes and objects in input image\n",
    "    img_no_holes = morphology.remove_small_holes(img_input)\n",
    "    img_no_objects = morphology.remove_small_objects(img_no_holes)\n",
    "   \n",
    "    # extract region properties\n",
    "    region_labels, labels_idx = label(img_no_objects, connectivity = 2, return_num = True)\n",
    "    props = regionprops(region_labels)\n",
    "\n",
    "    # define centroids for all regions and the central pixel as a target for selection\n",
    "    centroids = [prop.centroid for prop in props]\n",
    "    number_rows = img_input.shape[0]\n",
    "    central_row = np.round(number_rows / 2)\n",
    "    number_cols = img_input.shape[1]\n",
    "    central_col = np.round(number_cols / 2)\n",
    "    \n",
    "    img_max_area = np.zeros((img_no_objects.shape[0],img_no_objects.shape[1]),np.uint8)\n",
    "    center = (central_row,central_col)\n",
    "    index = 0\n",
    "    min_dist = 10000 \n",
    "   \n",
    "    # select the region closest to the central pixel by finding the nearest white pixel\n",
    "    for k in range(len(centroids)):     \n",
    "        coords = props[k].coords\n",
    "        nearest_coords = nearest_region_selection(coords,center)\n",
    "        current_dist = ((central_row - nearest_coords[0]) ** 2 + (central_col - nearest_coords[1]) ** 2) ** 0.5\n",
    "        if current_dist < min_dist:\n",
    "            min_dist = current_dist\n",
    "            index = k\n",
    "            \n",
    "    # find the bounding box of the selected region        \n",
    "    bounding_box = props[index].bbox\n",
    "    img_max_area[bounding_box[0]:bounding_box[2],bounding_box[1]:bounding_box[3]] = props[index].image\n",
    "\n",
    "    # correct the result by filling holes in the output\n",
    "    img_floodfill = img_max_area.copy()\n",
    "    height, width = img_input.shape[:2]\n",
    "    mask = np.zeros((height + 2,width + 2),np.uint8)\n",
    "    cv2.floodFill(img_floodfill,mask,(0,0),255)\n",
    "    img_floodfill_inv = cv2.bitwise_not(img_floodfill)\n",
    "    img_output = img_max_area | img_floodfill_inv\n",
    "\n",
    "    return img_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_region_selection (coords,target):\n",
    "    \n",
    "    # input arguments:\n",
    "    # coords - coordinates of the region of interest\n",
    "    # target - pixel coordinates for which we want to find the closest white pixel in the region\n",
    "    #\n",
    "    # output arguments:\n",
    "    # nearest_coords - coordinates of the nearest white pixel\n",
    "    \n",
    "    distances = np.sqrt((coords[:,0] - target[0]) ** 2 + (coords[:,1] - target[1]) ** 2)\n",
    "    nearest_index = np.argmin(distances)\n",
    "    \n",
    "    nearest_coords = coords[nearest_index]\n",
    "    \n",
    "    return nearest_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_index (img_segmented,img_groundtruth):\n",
    "    \n",
    "    # input arguments:\n",
    "    # img_segmented - segmented binary image\n",
    "    # img_groundtruth - binary groundtruth image\n",
    "    #\n",
    "    # output arguments:\n",
    "    # index - jaccard index \n",
    "    \n",
    "    # find the number of true positives, false positives and false negatives, required for jaccard index computation\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    \n",
    "    for i in range (img_segmented.shape[0]):\n",
    "        for j in range (img_segmented.shape[1]):\n",
    "            if (int(img_segmented[i][j]) > 0) & (int(img_groundtruth[i][j]) == 1):\n",
    "                TP += 1\n",
    "            elif (int(img_segmented[i][j]) > 0) & (int(img_groundtruth[i][j]) == 0):\n",
    "                FP += 1\n",
    "            elif (int(img_segmented[i][j]) == 0) & (int(img_groundtruth[i][j]) == 1):\n",
    "                FN += 1\n",
    "                \n",
    "    index = TP / (TP + FP + FN)\n",
    "    \n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all original images\n",
    "original_images_files = sorted(glob.glob(\".\\\\dataset\\\\images\\\\*.jpg\"))\n",
    "original_images = [cv2.imread(file) for file in original_images_files]\n",
    "\n",
    "# load all groundtruth images\n",
    "groundtruth_files = sorted(glob.glob(\".\\\\dataset\\\\groundtruths\\\\*.png\"))\n",
    "groundtruths = [cv2.imread(file) for file in groundtruth_files]\n",
    "for i in range (len(groundtruths)):\n",
    "    groundtruths[i] = color.rgb2gray(groundtruths[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define kernel for dilation\n",
    "kernel = np.ones((20,20),np.float32)/400\n",
    "\n",
    "result_images_meanshift = original_images.copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new folder to save the results\n",
    "path_meanshift = '.\\\\meanshift\\\\' \n",
    "if not os.path.exists(path_meanshift):\n",
    "    os.makedirs(path_meanshift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meanshift segmentation\n",
    "\n",
    "for i in range (len(original_images)):\n",
    "    result_images_meanshift[i] = hair_removal(original_images[i])\n",
    "    result_images_meanshift[i] = meanshift_segmentation(result_images_meanshift[i])   \n",
    "    result_images_meanshift[i] = region_extraction(result_images_meanshift[i])\n",
    "    result_images_meanshift[i] = cv2.dilate(result_images_meanshift[i],kernel,iterations = 1) \n",
    "    cv2.imwrite(path_meanshift + os.path.basename(original_images_files[i]), result_images_meanshift[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the jaccard index for the meanshift segmented images\n",
    "index_meanshift = []\n",
    "for i in range (len(result_images_meanshift)):\n",
    "    index_meanshift.append(jaccard_index(result_images_meanshift[i],groundtruths[i]))\n",
    "    \n",
    "plt.plot(index_meanshift)\n",
    "plt.show()\n",
    "print(index_meanshift)\n",
    "print(np.mean(index_meanshift))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all original images\n",
    "original_images_files = sorted(glob.glob(\".\\\\dataset\\\\images\\\\*.jpg\"))\n",
    "original_images = [cv2.imread(file) for file in original_images_files]\n",
    "\n",
    "# load all groundtruth images\n",
    "groundtruth_files = sorted(glob.glob(\".\\\\dataset\\\\groundtruths\\\\*.png\"))\n",
    "groundtruths = [cv2.imread(file) for file in groundtruth_files]\n",
    "for i in range (len(groundtruths)):\n",
    "    groundtruths[i] = color.rgb2gray(groundtruths[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define kernel for dilation\n",
    "kernel = np.ones((20,20),np.float32)/400\n",
    "\n",
    "result_images_watershed = original_images.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new folder to save the results\n",
    "path_watershed = '.\\\\watershed\\\\' \n",
    "if not os.path.exists(path_watershed):\n",
    "    os.makedirs(path_watershed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# watershed segmentation\n",
    "for i in range (len(original_images)):\n",
    "    result_images_watershed[i] = hair_removal(original_images[i])\n",
    "    result_images_watershed[i] = watershed_segmentation(original_images[i],result_images_watershed[i])   \n",
    "    result_images_watershed[i] = region_extraction(result_images_watershed[i])\n",
    "    result_images_watershed[i] = cv2.dilate(result_images_watershed[i],kernel,iterations = 1)    \n",
    "    cv2.imwrite(path_watershed + os.path.basename(original_images_files[i]), result_images_watershed[i])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the jaccard index for the watershed segmented images\n",
    "index_watershed = []\n",
    "for i in range (len(result_images_watershed)):\n",
    "    index_watershed.append(jaccard_index(result_images_watershed[i]/255,groundtruths[i]))\n",
    "    \n",
    "plt.plot(index_watershed)\n",
    "plt.show()\n",
    "print(index_watershed)\n",
    "print(np.mean(index_watershed)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
